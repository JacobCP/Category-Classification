{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final results: using alpha = .01, lambda = .0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Logistic regression: test accuracy ~.75, test cost ~.68\n",
    "    \n",
    "    NN - one hidden layer:\n",
    "        early stopping: test accuracy ~.79, test cost ~.55\n",
    "        \n",
    "    NN - two hidden layers:\n",
    "        early stopping: test accuracy ~.79 , test cost ~.54\n",
    "        regularization and early stopping: test accuracy ~.8, test cost ~.53       \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.00000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.126135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.52533</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151460</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.201720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15470.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46408.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       feat_1        feat_2        feat_3        feat_4  \\\n",
       "count  61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
       "mean   30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
       "std    17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
       "min        1.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%    15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
       "50%    30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%    46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
       "max    61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
       "\n",
       "             feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.071043      0.025696      0.193704      0.662433      1.011296   \n",
       "std        0.438902      0.215333      1.030102      2.255770      3.474822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max       19.000000     10.000000     38.000000     76.000000     43.000000   \n",
       "\n",
       "           ...            feat_84       feat_85       feat_86       feat_87  \\\n",
       "count      ...       61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       ...           0.070752      0.532306      1.128576      0.393549   \n",
       "std        ...           1.151460      1.900438      2.681554      1.575455   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      1.000000      0.000000   \n",
       "max        ...          76.000000     55.000000     65.000000     67.000000   \n",
       "\n",
       "            feat_88       feat_89       feat_90       feat_91       feat_92  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.874915      0.457772      0.812421      0.264941      0.380119   \n",
       "std        2.115466      1.527385      4.597804      2.045646      0.982385   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       30.000000     61.000000    130.000000     52.000000     19.000000   \n",
       "\n",
       "            feat_93  \n",
       "count  61878.000000  \n",
       "mean       0.126135  \n",
       "std        1.201720  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max       87.000000  \n",
       "\n",
       "[8 rows x 94 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~62K training examples. \n",
    "\n",
    "The features are a sparse matrix, with ~75% having zero values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data into shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the features and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (61878, 93)\n",
      "Y shape: (61878,)\n"
     ]
    }
   ],
   "source": [
    "X = train.loc[:, \"feat_1\":\"feat_93\"]\n",
    "Y = train.loc[:, \"target\"]\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"Y shape: \" + str(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Y shape: (61878, 9)\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoding = pd.get_dummies(Y)\n",
    "#Y = one_hot_encoding\n",
    "print(\"New Y shape: \" + str(one_hot_encoding.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's randomly shuffle them, so that we'll be able to do batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(train.index)\n",
    "shuffled_X = X.reindex(shuffle_index)\n",
    "shuffled_Y = Y.reindex(shuffle_index)\n",
    "shuffled_one_hot = one_hot_encoding.reindex(shuffle_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to split them into train/test sets.\n",
    "\n",
    "I've been led to believe that 10,000 should be more than enough for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features shape: (51878, 93)\n",
      "train labels shape: (51878, 9)\n",
      "\n",
      "test features shape: (10000, 93)\n",
      "test labels shape: (10000, 9)\n"
     ]
    }
   ],
   "source": [
    "test_size = 10000\n",
    "X_test = shuffled_X[0:test_size]\n",
    "X_train = shuffled_X[test_size:]\n",
    "Y_test = shuffled_one_hot[0:test_size]\n",
    "Y_train = shuffled_one_hot[test_size:]\n",
    "print(\"train features shape: \" + str(X_train.shape))\n",
    "print(\"train labels shape: \" + str(Y_train.shape))\n",
    "print(\"\")\n",
    "print(\"test features shape: \" + str(X_test.shape))\n",
    "print(\"test labels shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize the inputs by dividing by max of each feature, to get them between 0 and 1.  \n",
    "(We take those from the whole X, so it's consistent for the test set as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_X = X.max()\n",
    "#var_X = X.var()\n",
    "X_train_normalized = X_train.div(max_X, axis = 1)\n",
    "#X_train_normalized = X_train.div(var_X, axis = 1)\n",
    "\n",
    "X_test_normalized = X_test.div(max_X, axis = 1)\n",
    "#X_test_normalized = X_test.div(var_X, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready for tensorflow (choose one of the models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = tf.placeholder(tf.float32, [93, None]) # 93 by mini-batch size\n",
    "Y_batch = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([9, 93]) * tf.sqrt(2/138))\n",
    "b = tf.Variable(tf.random_uniform([9, 1]))\n",
    "\n",
    "Z = tf.matmul(W, X_batch) + b\n",
    "\n",
    "# we need to transpose them, to work with the cross_entropy function, so now they become of shape m * 9 instead\n",
    "Y_labels = tf.transpose(Y_batch)\n",
    "Y_logits = tf.transpose(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2 - NN, one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = tf.placeholder(tf.float32, [93, None]) # 93 by mini-batch size\n",
    "Y_batch = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([45, 93]) * tf.sqrt(2/138))\n",
    "b1 = tf.Variable(tf.random_uniform([45, 1]))\n",
    "\n",
    "Z1 = tf.matmul(W1, X_batch) + b1\n",
    "A1 = tf.nn.relu(Z1) # 45 by mini-batch size\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([9, 45]) * tf.sqrt(2/65))\n",
    "b2 = tf.Variable(tf.random_uniform([9, 1]))\n",
    "\n",
    "Z2 = tf.matmul(W2, A1) + b2\n",
    "\n",
    "# we need to transpose them, to work with the cross_entropy function, so now they become of shape m * 9 instead\n",
    "Y_labels = tf.transpose(Y_batch)\n",
    "Y_logits = tf.transpose(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3 - NN, 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = tf.placeholder(tf.float32, [93, None]) # 93 by mini-batch size\n",
    "Y_batch = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([45, 93]) * tf.sqrt(2/93))\n",
    "b1 = tf.Variable(tf.random_uniform([45, 1]))\n",
    "\n",
    "Z1 = tf.matmul(W1, X_batch) + b1\n",
    "A1 = tf.nn.relu(Z1) # 45 by mini-batch size\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([20, 45]) * tf.sqrt(2/45))\n",
    "b2 = tf.Variable(tf.random_uniform([20, 1]))\n",
    "\n",
    "Z2 = tf.matmul(W2, A1) + b2\n",
    "A2 = tf.nn.relu(Z2) # 20 by mini-batch size\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform([9, 20]) * tf.sqrt(2/45))\n",
    "b3 = tf.Variable(tf.random_uniform([9, 1]))\n",
    "\n",
    "Z3 = tf.matmul(W3, A2) + b3 # 9 by mini-batch size\n",
    "\n",
    "# we need to transpose them, to work with the cross_entropy function, so now they become of shape m * 9 instead\n",
    "Y_labels = tf.transpose(Y_batch)\n",
    "Y_logits = tf.transpose(Z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For all models, setting up training and evaluation (choose appropriate regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for training\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_labels, logits=Y_logits))\n",
    "\n",
    "# regularization...\n",
    "#lambd = .0001\n",
    "\n",
    "# for logistic regression\n",
    "#regularization = tf.nn.l2_loss(W)\n",
    "\n",
    "# for one-layer nn\n",
    "#regularization = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2)\n",
    "\n",
    "# for 2-layer nn\n",
    "#regularization = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(W2)\n",
    "\n",
    "#cross_entropy = cross_entropy + (regularization * lambd)\n",
    "\n",
    "# These are the predictions, and the actual labels, in a standardized form\n",
    "actual_predictions = tf.argmax(Y_logits, 1)\n",
    "actual_labels = tf.argmax(Y_labels, 1)\n",
    "\n",
    "# and this is for evaluation\n",
    "correct_prediction = tf.equal(actual_predictions, actual_labels)\n",
    "correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "# need to manually evaluate loss for the test set, where we're not training\n",
    "manual_softmax = tf.nn.softmax(logits=Y_logits)\n",
    "manual_mask = tf.equal(Y_labels, 1)\n",
    "manual_cost = tf.boolean_mask(manual_softmax, manual_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize variables for the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 3\n",
    "\n",
    "#train_step = tf.train.AdamOptimizer(alpha).minimize(cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(alpha).minimize(cross_entropy)\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_counts = [0]\n",
    "epoch_costs = [np.mean(np.log(manual_cost.eval({X_batch: np.transpose(X_test_normalized), \n",
    "                  Y_batch: np.transpose(Y_test)})) * -1)]\n",
    "epoch_test_costs = [np.mean(np.log(manual_cost.eval({X_batch: np.transpose(X_test_normalized), \n",
    "                  Y_batch: np.transpose(Y_test)})) * -1)]\n",
    "epoch_train_accuracies = []\n",
    "epoch_test_accuracies = []\n",
    "current_epoch = 0\n",
    "\n",
    "epoch_train_accuracies.append(accuracy.eval({X_batch: np.transpose(X_train_normalized), \n",
    "                                             Y_batch: np.transpose(Y_train)}))\n",
    "epoch_test_accuracies.append(accuracy.eval({X_batch: np.transpose(X_test_normalized), \n",
    "                                            Y_batch: np.transpose(Y_test)}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #10 | train accuracy: 0.68032694 ,cost: 1.0666190019020667 | test accuracy: 0.6793 ,cost: 1.0548421\n",
      "epoch #20 | train accuracy: 0.70388216 ,cost: 0.932797820522235 | test accuracy: 0.6992 ,cost: 0.9306674\n",
      "epoch #30 | train accuracy: 0.713231 ,cost: 0.8720884380432276 | test accuracy: 0.7089 ,cost: 0.87370616\n",
      "epoch #40 | train accuracy: 0.7188018 ,cost: 0.8359915614128113 | test accuracy: 0.7146 ,cost: 0.8398199\n",
      "epoch #50 | train accuracy: 0.7227341 ,cost: 0.8114697864422431 | test accuracy: 0.7189 ,cost: 0.81681687\n",
      "epoch #60 | train accuracy: 0.7265315 ,cost: 0.7934275854092377 | test accuracy: 0.7218 ,cost: 0.79989815\n",
      "epoch #70 | train accuracy: 0.72872895 ,cost: 0.7794344058403602 | test accuracy: 0.7244 ,cost: 0.7867746\n",
      "epoch #80 | train accuracy: 0.73042524 ,cost: 0.7681700518498054 | test accuracy: 0.7257 ,cost: 0.77620476\n",
      "epoch #90 | train accuracy: 0.732295 ,cost: 0.7588482533509915 | test accuracy: 0.7277 ,cost: 0.7674508\n",
      "epoch #100 | train accuracy: 0.7337985 ,cost: 0.750967835004513 | test accuracy: 0.7294 ,cost: 0.7600434\n",
      "epoch #110 | train accuracy: 0.7356105 ,cost: 0.7441919010419112 | test accuracy: 0.7304 ,cost: 0.7536671\n",
      "epoch #120 | train accuracy: 0.7368827 ,cost: 0.7382845775439189 | test accuracy: 0.7314 ,cost: 0.74810165\n",
      "epoch #130 | train accuracy: 0.7379429 ,cost: 0.7330749069268887 | test accuracy: 0.7323 ,cost: 0.74318755\n",
      "epoch #140 | train accuracy: 0.7389645 ,cost: 0.7284355484522306 | test accuracy: 0.7332 ,cost: 0.738806\n",
      "epoch #150 | train accuracy: 0.74006325 ,cost: 0.7242695265091382 | test accuracy: 0.7338 ,cost: 0.7348666\n",
      "epoch #160 | train accuracy: 0.7409692 ,cost: 0.7205014549768888 | test accuracy: 0.735 ,cost: 0.73129934\n",
      "epoch #170 | train accuracy: 0.74164385 ,cost: 0.7170716707523053 | test accuracy: 0.7366 ,cost: 0.7280486\n",
      "epoch #180 | train accuracy: 0.74222213 ,cost: 0.7139323972738706 | test accuracy: 0.7373 ,cost: 0.72507\n",
      "epoch #190 | train accuracy: 0.7430124 ,cost: 0.7110447528270575 | test accuracy: 0.7369 ,cost: 0.72232735\n",
      "epoch #200 | train accuracy: 0.7441112 ,cost: 0.708376774421105 | test accuracy: 0.7377 ,cost: 0.71979094\n",
      "epoch #210 | train accuracy: 0.744863 ,cost: 0.7059020205185964 | test accuracy: 0.7381 ,cost: 0.717436\n",
      "epoch #220 | train accuracy: 0.7454412 ,cost: 0.703598134792768 | test accuracy: 0.7386 ,cost: 0.71524197\n",
      "epoch #230 | train accuracy: 0.74617374 ,cost: 0.7014463864839994 | test accuracy: 0.7395 ,cost: 0.71319133\n",
      "epoch #240 | train accuracy: 0.7466749 ,cost: 0.6994307740376546 | test accuracy: 0.7397 ,cost: 0.7112692\n",
      "epoch #250 | train accuracy: 0.7469447 ,cost: 0.6975374852235501 | test accuracy: 0.7403 ,cost: 0.70946264\n",
      "epoch #260 | train accuracy: 0.747311 ,cost: 0.6957546827884821 | test accuracy: 0.7405 ,cost: 0.7077609\n",
      "epoch #270 | train accuracy: 0.7476387 ,cost: 0.69407213307344 | test accuracy: 0.7411 ,cost: 0.7061541\n",
      "epoch #280 | train accuracy: 0.7481013 ,cost: 0.6924807142752868 | test accuracy: 0.7418 ,cost: 0.7046341\n",
      "epoch #290 | train accuracy: 0.748429 ,cost: 0.690972660596554 | test accuracy: 0.7426 ,cost: 0.70319325\n",
      "epoch #300 | train accuracy: 0.7489687 ,cost: 0.6895408790845138 | test accuracy: 0.7435 ,cost: 0.7018253\n",
      "epoch #310 | train accuracy: 0.7493928 ,cost: 0.6881792694330215 | test accuracy: 0.7442 ,cost: 0.70052433\n",
      "epoch #320 | train accuracy: 0.7496627 ,cost: 0.6868823411372992 | test accuracy: 0.7445 ,cost: 0.6992853\n",
      "epoch #330 | train accuracy: 0.7499325 ,cost: 0.6856451011621035 | test accuracy: 0.7448 ,cost: 0.69810367\n",
      "epoch #340 | train accuracy: 0.75022167 ,cost: 0.6844632545342813 | test accuracy: 0.7447 ,cost: 0.6969752\n",
      "epoch #350 | train accuracy: 0.7505494 ,cost: 0.6833327802327963 | test accuracy: 0.7448 ,cost: 0.6958962\n",
      "epoch #360 | train accuracy: 0.75089633 ,cost: 0.6822501524136617 | test accuracy: 0.745 ,cost: 0.6948634\n",
      "epoch #370 | train accuracy: 0.7512433 ,cost: 0.6812120641653354 | test accuracy: 0.745 ,cost: 0.6938737\n",
      "epoch #380 | train accuracy: 0.75159025 ,cost: 0.6802156705122727 | test accuracy: 0.7454 ,cost: 0.6929243\n",
      "epoch #390 | train accuracy: 0.7520529 ,cost: 0.6792582021309779 | test accuracy: 0.746 ,cost: 0.6920128\n",
      "epoch #400 | train accuracy: 0.7524191 ,cost: 0.6783372805668757 | test accuracy: 0.7464 ,cost: 0.6911368\n",
      "epoch #410 | train accuracy: 0.75266975 ,cost: 0.6774506866931915 | test accuracy: 0.7472 ,cost: 0.69029415\n",
      "epoch #420 | train accuracy: 0.75280464 ,cost: 0.6765962976675767 | test accuracy: 0.7479 ,cost: 0.689483\n",
      "epoch #430 | train accuracy: 0.75319016 ,cost: 0.6757723333743902 | test accuracy: 0.748 ,cost: 0.68870145\n",
      "epoch #440 | train accuracy: 0.75340223 ,cost: 0.6749769965043435 | test accuracy: 0.7479 ,cost: 0.6879479\n",
      "epoch #450 | train accuracy: 0.75346005 ,cost: 0.6742087075343499 | test accuracy: 0.748 ,cost: 0.6872209\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "batches_in_epoch = int(X_train.shape[0] / batch_size)\n",
    "remainder = X_train.shape[0] % batch_size\n",
    "train_epochs = 450 # should be enough, see where the peek is, then rerun that amount\n",
    "\n",
    "\n",
    "batch_start = 0\n",
    "\n",
    "for i in range(train_epochs):\n",
    "    current_epoch += 1 # one-index based\n",
    "\n",
    "    step_cost = []\n",
    "    # train on the batches\n",
    "    for j in range(batches_in_epoch):\n",
    "        batch_start = j * batch_size\n",
    "        batch_end = batch_start + batch_size\n",
    "        _, iter_cost = session.run([train_step, cross_entropy], \n",
    "                                   {X_batch: np.transpose(X_train_normalized.iloc[batch_start:batch_end]), \n",
    "                                    Y_batch: np.transpose(Y_train.iloc[batch_start:batch_end])})\n",
    "        step_cost.append(iter_cost)\n",
    "\n",
    "            \n",
    "    # train on the remainder\n",
    "    batch_start = batches_in_epoch * batch_size\n",
    "    _, iter_cost = session.run([train_step, cross_entropy], \n",
    "                               {X_batch: np.transpose(X_train_normalized.iloc[batch_start:]), \n",
    "                                Y_batch: np.transpose(Y_train.iloc[batch_start:])})\n",
    "    step_cost.append(iter_cost)\n",
    "\n",
    "    # save the cost and accuracy for plotting every 10 epochs\n",
    "    if current_epoch % 10 == 0:\n",
    "        epoch_counts.append(current_epoch)\n",
    "        epoch_train_accuracies.append(accuracy.eval({X_batch: np.transpose(X_train_normalized), \n",
    "                                                     Y_batch: np.transpose(Y_train)}))\n",
    "        epoch_test_accuracies.append(accuracy.eval({X_batch: np.transpose(X_test_normalized), \n",
    "                                                     Y_batch: np.transpose(Y_test)}))\n",
    "        epoch_costs.append(sum(step_cost) / float(len(step_cost)))\n",
    "        epoch_test_costs.append(np.mean(np.log(manual_cost.eval({X_batch: np.transpose(X_test_normalized), \n",
    "                  Y_batch: np.transpose(Y_test)})) * -1))\n",
    "        print(\"epoch #\" + str(current_epoch), \n",
    "              \"| train accuracy: \" + str(epoch_train_accuracies[-1]), \",cost: \" + str(epoch_costs[-1]),\n",
    "              \"| test accuracy: \" + str(epoch_test_accuracies[-1]), \",cost: \" + str(epoch_test_costs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train accuracy after 450 epochs is: 0.7534600496292114\n",
      "final test accuracy after 450 epochs is: 0.7480000257492065\n",
      "final train cost after 450 epochs is: 0.6742087075343499\n",
      "final test cost after 450 epochs is: 0.6872208714485168\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x189dfce56a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epoch_start = 0\n",
    "epoch_end = len(epoch_test_accuracies)\n",
    "plt.plot(epoch_counts[epoch_start:], epoch_train_accuracies[epoch_start:], \"b\",\n",
    "         epoch_counts[epoch_start:], epoch_test_accuracies[epoch_start:], \"r\")\n",
    "print(\"final train accuracy after {} epochs is: {}\".format(epoch_counts[-1], epoch_train_accuracies[-1]))\n",
    "print(\"final test accuracy after {} epochs is: {}\".format(epoch_counts[-1], epoch_test_accuracies[-1]))\n",
    "print(\"final train cost after {} epochs is: {}\".format(epoch_counts[-1], epoch_costs[-1]))\n",
    "print(\"final test cost after {} epochs is: {}\".format(epoch_counts[-1], epoch_test_costs[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try some feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are black box features, hard to engineer.\n",
    "\n",
    "Still, some ideas...\n",
    "* get most important features, and create new features of the difference between them (would think that it doesn't add much for neural nets, that could learn linear features, but saw from someone that it's helpful.\n",
    "* binary features of whether feature is 0 or not.\n",
    "* binary features of whether combination of correlated features are present\n",
    "* binning values.\n",
    "* Saw that XGboost can be used to find new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's use scikit to do logistic regression, and get the most important features. Maybe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51878,)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_singlecol = Y_train.idxmax(axis = 1)\n",
    "Y_train_singlecol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.fit(X_train_normalized, Y_train_singlecol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is: 0.729731292648136\n"
     ]
    }
   ],
   "source": [
    "score = log_model.score(X_train_normalized, Y_train_singlecol)\n",
    "print(\"score is: {}\".format(score))\n",
    "coef = log_model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_copy = coef\n",
    "len(coef_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33, 10, 24, 13, 39, 16,  8, 14, 68, 66], dtype=int64)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_index = (abs(coef_copy) * -1).argsort()\n",
    "best_features = sort_index[0:10]\n",
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the most relevant features are the ones above.  \n",
    "let's make tuples of pairs of each of those, which will be a total of (10 * 9) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pairs = []\n",
    "for i in range(len(best_features)):\n",
    "    for j in range(i+1, len(best_features)):\n",
    "        feature_pairs.append((best_features[i], best_features[j]))\n",
    "len(feature_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of those pairs, let's make a new feature which is the difference between them.  \n",
    "We'll do it on the original pandas X dataframes, X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_X_train = X_train.copy()\n",
    "engineered_X_test = X_test.copy()\n",
    "\n",
    "feature_names = list(X_train)\n",
    "for feature_1, feature_2 in feature_pairs:\n",
    "    new_feature_name = feature_names[feature_1] + \" - \" + feature_names[feature_2] \n",
    "    engineered_X_train[new_feature_name] = engineered_X_train.iloc[:,feature_1] - engineered_X_train.iloc[:,feature_2]\n",
    "    \n",
    "for feature_1, feature_2 in feature_pairs:\n",
    "    new_feature_name = feature_names[feature_1] + \" - \" + feature_names[feature_2] \n",
    "    engineered_X_test[new_feature_name] = engineered_X_test.iloc[:,feature_1] - engineered_X_test.iloc[:,feature_2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a sparse matrix, so questionable how many of those features will be meaningful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge the groups for a total of X, for normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "engineered_X = engineered_X_test.append(engineered_X_train)\n",
    "max_engineered_X = engineered_X.max()\n",
    "engineered_X_train_normalized = engineered_X_train.div(max_engineered_X, axis = 1)\n",
    "engineered_X_test_normalized = engineered_X_test.div(max_engineered_X, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plug these values in to the non-engineered variables, so we can run the previous code on them.\n",
    "The only thing we need to change in the previous code when we run it is that instead of 93, we put in 93+45 = 138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = engineered_X_train_normalized\n",
    "X_test_normalized = engineered_X_test_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, go back up there and run things again (change the weight placeholder shapes from 93 to 138 etc.)\n",
    "\n",
    "Result: No improvement - actually descreased performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Analysis\n",
    "\n",
    "### Ok, now let's try doing manual logistic regression, and analyze the results to isolate where to focus in feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran manual logistic regression, using code above (gradientDescentOptimizer, no regularization, alpha=3, 500 epochs), until we got to ~.75 accuracy on the test set.\n",
    "\n",
    "Let's build datasets for analysis.  \n",
    "Let's make a dataset with three columns - prediction, actual labels, and whether prediction was correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_metrics = pd.DataFrame(data = actual_predictions.eval({X_batch: np.transpose(X_test_normalized)}), \n",
    "                                  columns = [\"predictions\"])\n",
    "prediction_metrics[\"labels\"] = pd.Series(actual_labels.eval({Y_batch: np.transpose(Y_test)}))\n",
    "prediction_metrics[\"correct_prediction\"] = prediction_metrics[\"predictions\"] == prediction_metrics[\"labels\"]\n",
    "#prediction_metrics[~prediction_metrics[\"correct_prediction\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's join them to the X_test_normalized dataset  \n",
    "\n",
    "For that, we need to reset the index for X_test_normalized, and then join them on the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normalized = X_test_normalized.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_analysis = pd.concat([X_test_normalized, prediction_metrics], axis=1, join_axes=[X_test_normalized.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the index row - not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_analysis = X_test_analysis.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's make a simple bar plot of the different classes in:  \n",
    "1. the entire test group\n",
    "2. the group where it was predicted incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x189dfce4e80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x189e01c0e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_order = [i for i in range(9)]\n",
    "X_test_analysis[\"labels\"].value_counts().loc[numbers_order].plot(kind=\"bar\", title = \"Counts of Instances by Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x189e04f05c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x189e04c8128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_analysis[~X_test_analysis[\"correct_prediction\"]][\"labels\"].value_counts().loc[numbers_order].plot(kind=\"bar\",\n",
    "                                                                title = \"Counts of Incorrect Classification Instances by Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the classes are really skewed!  \n",
    "Makes it hard to interpret the incorrect classification counts.  \n",
    "\n",
    "Let's standardize them, and look at the percentage of instances that were incorrectly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x189eb287048>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x189eb27e748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_counts = X_test_analysis[\"labels\"].value_counts().loc[numbers_order]\n",
    "incorrect_counts = X_test_analysis[~X_test_analysis[\"correct_prediction\"]][\"labels\"].value_counts().loc[numbers_order]\n",
    "incorrect_percentages = incorrect_counts / total_counts\n",
    "incorrect_plot = (incorrect_percentages * 100).plot(kind=\"bar\", title = \"Percentage of Incorrect Classification Instances by Class\")\n",
    "incorrect_plot.set_yticklabels([str(i) + \"%\" for i in range(0,100,10)])\n",
    "incorrect_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, classes 1, 3 and 4 are the most misclassified (~80%), with class 7 somewhat less (~50%).  \n",
    "\n",
    "Of those, class 3 misclassification has the biggest effect on the bottom line, because it is a common class, so it makes sense to begin our focus on feature engineering there.\n",
    "\n",
    "Classes 1, 4 and 7 are all infrequent classes, which suggests that perhaps we've \"underlearnt\" for those classes.  \n",
    "Perhaps the algorithm gave more preference to getting correct predictions for other, more common classes.\n",
    "\n",
    "Let's see which class labels the algorithm provides for the misclassified instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x189eb2f4048>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x189e04c84a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_analysis[~X_test_analysis[\"correct_prediction\"]][\"predictions\"].value_counts().loc[numbers_order].plot(kind=\"bar\",\n",
    "                                                            title = \"Class Prediction counts for Misclassified Instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority are classified as class_2, which is the most frequently occuring class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In summary:\n",
    "1. The model is leaning excessively towards class_2, because there are so many instances of it - practically all the mislabeled instances.\n",
    "2. Conversely, it's performing poorly for several uncommonly occurring classes, namely: 1, 4 and 7.\n",
    "3. It's performing poorly for class_3, despite it being a commonly occuring class, and this has a bigger effect on the general accuracy of the model.\n",
    "4. It would seem that class_3 is hard to learn, or at least hard to differentiate from class_2.\n",
    "\n",
    "####  A few ideas:\n",
    "1. Let's try training the model without the instances of class_2, and see if accuracy improves for class_3.\n",
    "2. Let's analyze the weights for class_2 and class_3 prediction (including the weights in class_3 prediction when training without class_2 instances), to see where there's an overlap, and see if feature-engineering on those features can improve accuracy for class_3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
