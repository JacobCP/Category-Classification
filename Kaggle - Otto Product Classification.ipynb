{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final results: using alpha = .01, lambda = .0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Logistic regression: test accuracy ~.75, test cost ~.68\n",
    "    \n",
    "    NN - one hidden layer:\n",
    "        early stopping: test accuracy ~.79, test cost ~.55\n",
    "        \n",
    "    NN - two hidden layers:\n",
    "        early stopping: test accuracy ~.79 , test cost ~.54\n",
    "        regularization and early stopping: test accuracy ~.8, test cost ~.53       \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.00000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.126135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.52533</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151460</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.201720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15470.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46408.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       feat_1        feat_2        feat_3        feat_4  \\\n",
       "count  61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
       "mean   30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
       "std    17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
       "min        1.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%    15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
       "50%    30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%    46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
       "max    61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
       "\n",
       "             feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.071043      0.025696      0.193704      0.662433      1.011296   \n",
       "std        0.438902      0.215333      1.030102      2.255770      3.474822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max       19.000000     10.000000     38.000000     76.000000     43.000000   \n",
       "\n",
       "           ...            feat_84       feat_85       feat_86       feat_87  \\\n",
       "count      ...       61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       ...           0.070752      0.532306      1.128576      0.393549   \n",
       "std        ...           1.151460      1.900438      2.681554      1.575455   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      1.000000      0.000000   \n",
       "max        ...          76.000000     55.000000     65.000000     67.000000   \n",
       "\n",
       "            feat_88       feat_89       feat_90       feat_91       feat_92  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.874915      0.457772      0.812421      0.264941      0.380119   \n",
       "std        2.115466      1.527385      4.597804      2.045646      0.982385   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       30.000000     61.000000    130.000000     52.000000     19.000000   \n",
       "\n",
       "            feat_93  \n",
       "count  61878.000000  \n",
       "mean       0.126135  \n",
       "std        1.201720  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max       87.000000  \n",
       "\n",
       "[8 rows x 94 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~62K training examples. \n",
    "\n",
    "The features are a sparse matrix, with ~75% having zero values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data into shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the features and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (61878, 93)\n",
      "Y shape: (61878,)\n"
     ]
    }
   ],
   "source": [
    "X = train.loc[:, \"feat_1\":\"feat_93\"]\n",
    "Y = train.loc[:, \"target\"]\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"Y shape: \" + str(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Y shape: (61878, 9)\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoding = pd.get_dummies(Y)\n",
    "#Y = one_hot_encoding\n",
    "print(\"New Y shape: \" + str(one_hot_encoding.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's randomly shuffle them, so that we'll be able to do batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(train.index)\n",
    "shuffled_X = X.reindex(shuffle_index)\n",
    "shuffled_Y = Y.reindex(shuffle_index)\n",
    "shuffled_one_hot = one_hot_encoding.reindex(shuffle_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to split them into train/test sets.\n",
    "\n",
    "I've been led to believe that 10,000 should be more than enough for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features shape: (51878, 93)\n",
      "train labels shape: (51878, 9)\n",
      "\n",
      "test features shape: (10000, 93)\n",
      "test labels shape: (10000, 9)\n"
     ]
    }
   ],
   "source": [
    "test_size = 10000\n",
    "X_test = shuffled_X[0:test_size]\n",
    "X_train = shuffled_X[test_size:]\n",
    "Y_test = shuffled_one_hot[0:test_size]\n",
    "Y_train = shuffled_one_hot[test_size:]\n",
    "print(\"train features shape: \" + str(X_train.shape))\n",
    "print(\"train labels shape: \" + str(Y_train.shape))\n",
    "print(\"\")\n",
    "print(\"test features shape: \" + str(X_test.shape))\n",
    "print(\"test labels shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize the inputs by dividing by max of each feature, to get them between 0 and 1.  \n",
    "(We take those from the whole X, so it's consistent for the test set as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_X = X.max()\n",
    "#var_X = X.var()\n",
    "X_train_normalized = X_train.div(max_X, axis = 1)\n",
    "#X_train_normalized = X_train.div(var_X, axis = 1)\n",
    "\n",
    "X_test_normalized = X_test.div(max_X, axis = 1)\n",
    "#X_test_normalized = X_test.div(var_X, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready for tensorflow (choose one of the models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = tf.placeholder(tf.float32, [93, None]) # 93 by mini-batch size\n",
    "Y_batch = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([9, 93]) * tf.sqrt(2/138))\n",
    "b = tf.Variable(tf.random_uniform([9, 1]))\n",
    "\n",
    "Z = tf.matmul(W, X_batch) + b\n",
    "\n",
    "# we need to transpose them, to work with the cross_entropy function, so now they become of shape m * 9 instead\n",
    "Y_labels = tf.transpose(Y_batch)\n",
    "Y_logits = tf.transpose(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2 - NN, one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = tf.placeholder(tf.float32, [93, None]) # 93 by mini-batch size\n",
    "Y_batch = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([45, 93]) * tf.sqrt(2/138))\n",
    "b1 = tf.Variable(tf.random_uniform([45, 1]))\n",
    "\n",
    "Z1 = tf.matmul(W1, X_batch) + b1\n",
    "A1 = tf.nn.relu(Z1) # 45 by mini-batch size\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([9, 45]) * tf.sqrt(2/65))\n",
    "b2 = tf.Variable(tf.random_uniform([9, 1]))\n",
    "\n",
    "Z2 = tf.matmul(W2, A1) + b2\n",
    "\n",
    "# we need to transpose them, to work with the cross_entropy function, so now they become of shape m * 9 instead\n",
    "Y_labels = tf.transpose(Y_batch)\n",
    "Y_logits = tf.transpose(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3 - NN, 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = tf.placeholder(tf.float32, [93, None]) # 93 by mini-batch size\n",
    "Y_batch = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([45, 93]) * tf.sqrt(2/93))\n",
    "b1 = tf.Variable(tf.random_uniform([45, 1]))\n",
    "\n",
    "Z1 = tf.matmul(W1, X_batch) + b1\n",
    "A1 = tf.nn.relu(Z1) # 45 by mini-batch size\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([20, 45]) * tf.sqrt(2/45))\n",
    "b2 = tf.Variable(tf.random_uniform([20, 1]))\n",
    "\n",
    "Z2 = tf.matmul(W2, A1) + b2\n",
    "A2 = tf.nn.relu(Z2) # 20 by mini-batch size\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform([9, 20]) * tf.sqrt(2/45))\n",
    "b3 = tf.Variable(tf.random_uniform([9, 1]))\n",
    "\n",
    "Z3 = tf.matmul(W3, A2) + b3 # 9 by mini-batch size\n",
    "\n",
    "# we need to transpose them, to work with the cross_entropy function, so now they become of shape m * 9 instead\n",
    "Y_labels = tf.transpose(Y_batch)\n",
    "Y_logits = tf.transpose(Z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For all models, setting up training and evaluation (choose appropriate regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for training\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_labels, logits=Y_logits))\n",
    "\n",
    "# regularization...\n",
    "#lambd = .0001\n",
    "\n",
    "# for logistic regression\n",
    "#regularization = tf.nn.l2_loss(W)\n",
    "\n",
    "# for one-layer nn\n",
    "#regularization = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2)\n",
    "\n",
    "# for 2-layer nn\n",
    "#regularization = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(W2)\n",
    "\n",
    "#cross_entropy = cross_entropy + (regularization * lambd)\n",
    "\n",
    "# These are the predictions, and the actual labels, in a standardized form\n",
    "actual_predictions = tf.argmax(Y_logits, 1)\n",
    "actual_labels = tf.argmax(Y_labels, 1)\n",
    "\n",
    "# and this is for evaluation\n",
    "correct_prediction = tf.equal(actual_predictions, actual_labels)\n",
    "correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "# need to manually evaluate loss for the test set, where we're not training\n",
    "manual_softmax = tf.nn.softmax(logits=Y_logits)\n",
    "manual_mask = tf.equal(Y_labels, 1)\n",
    "manual_cost = tf.boolean_mask(manual_softmax, manual_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize variables for the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 3\n",
    "\n",
    "#train_step = tf.train.AdamOptimizer(alpha).minimize(cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(alpha).minimize(cross_entropy)\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_counts = [0]\n",
    "epoch_costs = [np.mean(np.log(manual_cost.eval({X_batch: np.transpose(X_test_normalized), \n",
    "                  Y_batch: np.transpose(Y_test)})) * -1)]\n",
    "epoch_test_costs = [np.mean(np.log(manual_cost.eval({X_batch: np.transpose(X_test_normalized), \n",
    "                  Y_batch: np.transpose(Y_test)})) * -1)]\n",
    "epoch_train_accuracies = []\n",
    "epoch_test_accuracies = []\n",
    "current_epoch = 0\n",
    "\n",
    "epoch_train_accuracies.append(accuracy.eval({X_batch: np.transpose(X_train_normalized), \n",
    "                                             Y_batch: np.transpose(Y_train)}))\n",
    "epoch_test_accuracies.append(accuracy.eval({X_batch: np.transpose(X_test_normalized), \n",
    "                                            Y_batch: np.transpose(Y_test)}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #10 | train accuracy: 0.6799414 ,cost: 1.0670315222098277 | test accuracy: 0.6827 ,cost: 1.0502864\n",
      "epoch #20 | train accuracy: 0.70214736 ,cost: 0.9332428563099641 | test accuracy: 0.7054 ,cost: 0.9262076\n",
      "epoch #30 | train accuracy: 0.71155405 ,cost: 0.8727103162270325 | test accuracy: 0.7151 ,cost: 0.8689873\n",
      "epoch #40 | train accuracy: 0.71754885 ,cost: 0.8367579109393634 | test accuracy: 0.7202 ,cost: 0.8347258\n",
      "epoch #50 | train accuracy: 0.7215197 ,cost: 0.8123434014045275 | test accuracy: 0.725 ,cost: 0.8113599\n",
      "epoch #60 | train accuracy: 0.7249123 ,cost: 0.7943808275919694 | test accuracy: 0.7284 ,cost: 0.79412425\n",
      "epoch #70 | train accuracy: 0.7281121 ,cost: 0.7804470073718291 | test accuracy: 0.7304 ,cost: 0.78073084\n",
      "epoch #80 | train accuracy: 0.73069507 ,cost: 0.7692264857200476 | test accuracy: 0.7311 ,cost: 0.76993173\n",
      "epoch #90 | train accuracy: 0.73190945 ,cost: 0.7599363911610383 | test accuracy: 0.7327 ,cost: 0.7609822\n",
      "epoch #100 | train accuracy: 0.7334901 ,cost: 0.7520779497348345 | test accuracy: 0.7332 ,cost: 0.753407\n",
      "epoch #110 | train accuracy: 0.7349165 ,cost: 0.7453162257487957 | test accuracy: 0.7348 ,cost: 0.74688655\n",
      "epoch #120 | train accuracy: 0.73634297 ,cost: 0.7394167941350204 | test accuracy: 0.736 ,cost: 0.74119705\n",
      "epoch #130 | train accuracy: 0.7373068 ,cost: 0.7342100315369092 | test accuracy: 0.7378 ,cost: 0.73617625\n",
      "epoch #140 | train accuracy: 0.738232 ,cost: 0.7295696185185359 | test accuracy: 0.7391 ,cost: 0.7317032\n",
      "epoch #150 | train accuracy: 0.73961985 ,cost: 0.7253993818393121 | test accuracy: 0.7407 ,cost: 0.72768587\n",
      "epoch #160 | train accuracy: 0.74069935 ,cost: 0.7216245910296073 | test accuracy: 0.7409 ,cost: 0.72405237\n",
      "epoch #170 | train accuracy: 0.741374 ,cost: 0.7181861136968319 | test accuracy: 0.7422 ,cost: 0.7207458\n",
      "epoch #180 | train accuracy: 0.7424149 ,cost: 0.71503662948425 | test accuracy: 0.7429 ,cost: 0.7177207\n",
      "epoch #190 | train accuracy: 0.7431281 ,cost: 0.7121376441075251 | test accuracy: 0.7436 ,cost: 0.7149399\n",
      "epoch #200 | train accuracy: 0.7438606 ,cost: 0.7094574570655823 | test accuracy: 0.7447 ,cost: 0.7123727\n",
      "epoch #210 | train accuracy: 0.7444003 ,cost: 0.7069697953187503 | test accuracy: 0.7455 ,cost: 0.7099938\n",
      "epoch #220 | train accuracy: 0.7452292 ,cost: 0.704652570761167 | test accuracy: 0.7458 ,cost: 0.70778173\n",
      "epoch #230 | train accuracy: 0.7457689 ,cost: 0.7024871844511765 | test accuracy: 0.7466 ,cost: 0.7057186\n",
      "epoch #240 | train accuracy: 0.74655926 ,cost: 0.7004576852688422 | test accuracy: 0.7467 ,cost: 0.7037887\n",
      "epoch #250 | train accuracy: 0.7468484 ,cost: 0.6985505085725051 | test accuracy: 0.747 ,cost: 0.701979\n",
      "epoch #260 | train accuracy: 0.7473688 ,cost: 0.6967537769904504 | test accuracy: 0.7476 ,cost: 0.700278\n",
      "epoch #270 | train accuracy: 0.7476387 ,cost: 0.6950573944128476 | test accuracy: 0.7484 ,cost: 0.69867575\n",
      "epoch #280 | train accuracy: 0.7480242 ,cost: 0.6934523295897704 | test accuracy: 0.7492 ,cost: 0.6971636\n",
      "epoch #290 | train accuracy: 0.74854463 ,cost: 0.6919307422179443 | test accuracy: 0.7491 ,cost: 0.6957338\n",
      "epoch #300 | train accuracy: 0.7489109 ,cost: 0.6904857147198457 | test accuracy: 0.7496 ,cost: 0.69437957\n",
      "epoch #310 | train accuracy: 0.7491229 ,cost: 0.6891111043783334 | test accuracy: 0.7498 ,cost: 0.69309497\n",
      "epoch #320 | train accuracy: 0.7492772 ,cost: 0.687801426419845 | test accuracy: 0.75 ,cost: 0.69187456\n",
      "epoch #330 | train accuracy: 0.7493928 ,cost: 0.6865517840935633 | test accuracy: 0.7506 ,cost: 0.6907137\n",
      "epoch #340 | train accuracy: 0.7499133 ,cost: 0.6853578503315265 | test accuracy: 0.7503 ,cost: 0.68960786\n",
      "epoch #350 | train accuracy: 0.75004816 ,cost: 0.6842156201601028 | test accuracy: 0.7506 ,cost: 0.68855333\n",
      "epoch #360 | train accuracy: 0.7502795 ,cost: 0.6831215585653598 | test accuracy: 0.7509 ,cost: 0.6875464\n",
      "epoch #370 | train accuracy: 0.75047225 ,cost: 0.6820724617976409 | test accuracy: 0.7514 ,cost: 0.68658406\n",
      "epoch #380 | train accuracy: 0.7508578 ,cost: 0.6810653026287372 | test accuracy: 0.7515 ,cost: 0.6856633\n",
      "epoch #390 | train accuracy: 0.75105053 ,cost: 0.6800974905490875 | test accuracy: 0.7521 ,cost: 0.6847814\n",
      "epoch #400 | train accuracy: 0.7513011 ,cost: 0.6791665496734473 | test accuracy: 0.7521 ,cost: 0.6839358\n",
      "epoch #410 | train accuracy: 0.751571 ,cost: 0.6782702482663668 | test accuracy: 0.7525 ,cost: 0.68312454\n",
      "epoch #420 | train accuracy: 0.75186014 ,cost: 0.6774065276751151 | test accuracy: 0.7526 ,cost: 0.6823454\n",
      "epoch #430 | train accuracy: 0.7520529 ,cost: 0.6765734828435458 | test accuracy: 0.753 ,cost: 0.68159646\n",
      "epoch #440 | train accuracy: 0.7524384 ,cost: 0.6757693944069055 | test accuracy: 0.753 ,cost: 0.6808759\n",
      "epoch #450 | train accuracy: 0.75265044 ,cost: 0.6749926679409467 | test accuracy: 0.7534 ,cost: 0.6801822\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-eb51397a0e01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         _, iter_cost = session.run([train_step, cross_entropy], \n\u001b[0;32m     18\u001b[0m                                    {X_batch: np.transpose(X_train_normalized.iloc[batch_start:batch_end]), \n\u001b[1;32m---> 19\u001b[1;33m                                     Y_batch: np.transpose(Y_train.iloc[batch_start:batch_end])})\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mstep_cost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "batches_in_epoch = int(X_train.shape[0] / batch_size)\n",
    "remainder = X_train.shape[0] % batch_size\n",
    "train_epochs = 500 # should be enough, see where the peek is, then rerun that amount\n",
    "\n",
    "\n",
    "batch_start = 0\n",
    "\n",
    "for i in range(train_epochs):\n",
    "    current_epoch += 1 # one-index based\n",
    "\n",
    "    step_cost = []\n",
    "    # train on the batches\n",
    "    for j in range(batches_in_epoch):\n",
    "        batch_start = j * batch_size\n",
    "        batch_end = batch_start + batch_size\n",
    "        _, iter_cost = session.run([train_step, cross_entropy], \n",
    "                                   {X_batch: np.transpose(X_train_normalized.iloc[batch_start:batch_end]), \n",
    "                                    Y_batch: np.transpose(Y_train.iloc[batch_start:batch_end])})\n",
    "        step_cost.append(iter_cost)\n",
    "\n",
    "            \n",
    "    # train on the remainder\n",
    "    batch_start = batches_in_epoch * batch_size\n",
    "    _, iter_cost = session.run([train_step, cross_entropy], \n",
    "                               {X_batch: np.transpose(X_train_normalized.iloc[batch_start:]), \n",
    "                                Y_batch: np.transpose(Y_train.iloc[batch_start:])})\n",
    "    step_cost.append(iter_cost)\n",
    "\n",
    "    # save the cost and accuracy for plotting every 10 epochs\n",
    "    if current_epoch % 10 == 0:\n",
    "        epoch_counts.append(current_epoch)\n",
    "        epoch_train_accuracies.append(accuracy.eval({X_batch: np.transpose(X_train_normalized), \n",
    "                                                     Y_batch: np.transpose(Y_train)}))\n",
    "        epoch_test_accuracies.append(accuracy.eval({X_batch: np.transpose(X_test_normalized), \n",
    "                                                     Y_batch: np.transpose(Y_test)}))\n",
    "        epoch_costs.append(sum(step_cost) / float(len(step_cost)))\n",
    "        epoch_test_costs.append(np.mean(np.log(manual_cost.eval({X_batch: np.transpose(X_test_normalized), \n",
    "                  Y_batch: np.transpose(Y_test)})) * -1))\n",
    "        print(\"epoch #\" + str(current_epoch), \n",
    "              \"| train accuracy: \" + str(epoch_train_accuracies[-1]), \",cost: \" + str(epoch_costs[-1]),\n",
    "              \"| test accuracy: \" + str(epoch_test_accuracies[-1]), \",cost: \" + str(epoch_test_costs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train accuracy after 150 epochs is: 0.8356528878211975\n",
      "final test accuracy after 150 epochs is: 0.788100004196167\n",
      "final train cost after 150 epochs is: 0.4101850470671287\n",
      "final test cost after 150 epochs is: 0.5970072746276855\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ddb42cf5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epoch_start = 0\n",
    "epoch_end = len(epoch_test_accuracies)\n",
    "plt.plot(epoch_counts[epoch_start:], epoch_train_accuracies[epoch_start:], \"b\",\n",
    "         epoch_counts[epoch_start:], epoch_test_accuracies[epoch_start:], \"r\")\n",
    "print(\"final train accuracy after {} epochs is: {}\".format(epoch_counts[-1], epoch_train_accuracies[-1]))\n",
    "print(\"final test accuracy after {} epochs is: {}\".format(epoch_counts[-1], epoch_test_accuracies[-1]))\n",
    "print(\"final train cost after {} epochs is: {}\".format(epoch_counts[-1], epoch_costs[-1]))\n",
    "print(\"final test cost after {} epochs is: {}\".format(epoch_counts[-1], epoch_test_costs[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try some feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are black box features, hard to engineer.\n",
    "\n",
    "Still, some ideas...\n",
    "* get most important features, and create new features of the difference between them (would think that it doesn't add much for neural nets, that could learn linear features, but saw from someone that it's helpful.\n",
    "* binary features of whether feature is 0 or not.\n",
    "* binary features of whether combination of correlated features are present\n",
    "* binning values.\n",
    "* Saw that XGboost can be used to find new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's use scikit to do logistic regression, and get the most important features. Maybe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51878,)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_singlecol = Y_train.idxmax(axis = 1)\n",
    "Y_train_singlecol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.fit(X_train_normalized, Y_train_singlecol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is: 0.729731292648136\n"
     ]
    }
   ],
   "source": [
    "score = log_model.score(X_train_normalized, Y_train_singlecol)\n",
    "print(\"score is: {}\".format(score))\n",
    "coef = log_model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_copy = coef\n",
    "len(coef_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33, 10, 24, 13, 39, 16,  8, 14, 68, 66], dtype=int64)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_index = (abs(coef_copy) * -1).argsort()\n",
    "best_features = sort_index[0:10]\n",
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the most relevant features are the ones above.  \n",
    "let's make tuples of pairs of each of those, which will be a total of (10 * 9) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pairs = []\n",
    "for i in range(len(best_features)):\n",
    "    for j in range(i+1, len(best_features)):\n",
    "        feature_pairs.append((best_features[i], best_features[j]))\n",
    "len(feature_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of those pairs, let's make a new feature which is the difference between them.  \n",
    "We'll do it on the original pandas X dataframes, X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_X_train = X_train.copy()\n",
    "engineered_X_test = X_test.copy()\n",
    "\n",
    "feature_names = list(X_train)\n",
    "for feature_1, feature_2 in feature_pairs:\n",
    "    new_feature_name = feature_names[feature_1] + \" - \" + feature_names[feature_2] \n",
    "    engineered_X_train[new_feature_name] = engineered_X_train.iloc[:,feature_1] - engineered_X_train.iloc[:,feature_2]\n",
    "    \n",
    "for feature_1, feature_2 in feature_pairs:\n",
    "    new_feature_name = feature_names[feature_1] + \" - \" + feature_names[feature_2] \n",
    "    engineered_X_test[new_feature_name] = engineered_X_test.iloc[:,feature_1] - engineered_X_test.iloc[:,feature_2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a sparse matrix, so questionable how many of those features will be meaningful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge the groups for a total of X, for normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "engineered_X = engineered_X_test.append(engineered_X_train)\n",
    "max_engineered_X = engineered_X.max()\n",
    "engineered_X_train_normalized = engineered_X_train.div(max_engineered_X, axis = 1)\n",
    "engineered_X_test_normalized = engineered_X_test.div(max_engineered_X, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plug these values in to the non-engineered variables, so we can run the previous code on them.\n",
    "The only thing we need to change in the previous code when we run it is that instead of 93, we put in 93+45 = 138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = engineered_X_train_normalized\n",
    "X_test_normalized = engineered_X_test_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, go back up there and run things again (change the weight placeholder shapes from 93 to 138 etc.)\n",
    "\n",
    "Result: No improvement - actually descreased performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Analysis\n",
    "\n",
    "### Ok, now let's try doing manual logistic regression, and analyze the results to isolate where to focus in feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran manual logistic regression, using code above (gradientDescentOptimizer, no regularization, alpha=3, 500 epochs), until we got to ~.75 accuracy on the test set.\n",
    "\n",
    "Let's build datasets for analysis.  \n",
    "Let's make a dataset with three columns - prediction, actual labels, and whether prediction was correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_metrics = pd.DataFrame(data = actual_predictions.eval({X_batch: np.transpose(X_test_normalized)}), \n",
    "                                  columns = [\"predictions\"])\n",
    "prediction_metrics[\"labels\"] = pd.Series(actual_labels.eval({Y_batch: np.transpose(Y_test)}))\n",
    "prediction_metrics[\"correct_prediction\"] = prediction_metrics[\"predictions\"] == prediction_metrics[\"labels\"]\n",
    "#prediction_metrics[~prediction_metrics[\"correct_prediction\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's join them to the X_test_normalized dataset  \n",
    "\n",
    "For that, we need to reset the index for X_test_normalized, and then join them on the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normalized = X_test_normalized.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_analysis = pd.concat([X_test_normalized, prediction_metrics], axis=1, join_axes=[X_test_normalized.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the index row - not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_analysis = X_test_analysis.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's make a simple bar plot of the different classes in:  \n",
    "1. the entire test group\n",
    "2. the group where it was predicted incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1df5c6e3c18>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df5c6537f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_order = [i for i in range(9)]\n",
    "X_test_analysis[\"labels\"].value_counts().loc[numbers_order].plot(kind=\"bar\", title = \"Counts of Instances by Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1df5cd8ad30>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df5c81ecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_analysis[~X_test_analysis[\"correct_prediction\"]][\"labels\"].value_counts().loc[numbers_order].plot(kind=\"bar\",\n",
    "                                                                title = \"Counts of Incorrect Classification Instances by Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the classes are really skewed!  \n",
    "Makes it hard to interpret the incorrect classification counts.  \n",
    "\n",
    "Let's standardize them, and look at the percentage of instances that were incorrectly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1df5ce18d68>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df5cd5fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_counts = X_test_analysis[\"labels\"].value_counts().loc[numbers_order]\n",
    "incorrect_counts = X_test_analysis[~X_test_analysis[\"correct_prediction\"]][\"labels\"].value_counts().loc[numbers_order]\n",
    "incorrect_percentages = incorrect_counts / total_counts\n",
    "incorrect_plot = (incorrect_percentages * 100).plot(kind=\"bar\", title = \"Percentage of Incorrect Classification Instances by Class\")\n",
    "incorrect_plot.set_yticklabels([\"0%\", \"20%\", \"40%\", \"60%\", \"80%\"])\n",
    "incorrect_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, classes 1, 3 and 4 are the most misclassified (>80%), with class 7 somewhat less (~60%).  \n",
    "\n",
    "Of those, class 3 misclassification has the biggest effect on the bottom line, because it is a common class, so it makes sense to begin our focus on feature engineering there.\n",
    "\n",
    "Classes 1, 4 and 7 are all infrequent classes, which suggests that perhaps we've \"underlearnt\" for those classes.  \n",
    "Perhaps the algorithm gave more preference to getting correct predictions for other, more common classes.\n",
    "\n",
    "Let's see which class labels the algorithm provides for the misclassified instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1df5aba6908>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df5abf1320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_analysis[~X_test_analysis[\"correct_prediction\"]][\"predictions\"].value_counts().loc[numbers_orders].plot(kind=\"bar\",\n",
    "                                                            title = \"Class Prediction counts for Misclassified Instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority are classified as class_2, which is the most frequently occuring class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In summary:\n",
    "1. The model is leaning excessively towards class_2, because there are so many instances of it - practically all the mislabeled instances.\n",
    "2. Conversely, it's performing poorly for several uncommonly occurring classes, namely: 1, 4 and 7.\n",
    "3. It's performing poorly for class_3, despite it being a commonly occuring class, and this has a bigger effect on the general accuracy of the model.\n",
    "4. It would seem that class_3 is hard to learn, or at least hard to differentiate from class_2.\n",
    "\n",
    "####  A few ideas:\n",
    "1. Let's try training the model without the instances of class_2, and see if accuracy improves for class_3.\n",
    "2. Let's analyze the weights for class_2 and class_3 prediction (including the weights in class_3 prediction when training without class_2 instances), to see where there's an overlap, and see if feature-engineering on those features can improve accuracy for class_3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
